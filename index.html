<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
<title>Wind-on-Wall — WebRender Fill</title>
<style>
  html,body{height:100%;margin:0;background:#000}
  .root{position:fixed;inset:0;background:#000}
  canvas{position:absolute;inset:0;width:100%;height:100%;object-fit:fill;background:#000}
</style>
</head>
<body>
  <div class="root">
    <canvas id="view"></canvas>
    <canvas id="stain"></canvas>
  </div>

<script>
/* Fixed params from your screenshot */
const PARAMS = {
  dt: 2.0,         // seconds
  thr: 60,         // diff threshold
  blur: 0,         // px
  grey: 60,        // grey level (0–255)
  stainOn: true,
  decay: 0.930,    // residual decay
  strength: 0.35,  // residual strength
  color: "#ffffff" // residual color
};

(async function(){
  const view = document.getElementById('view');
  const vctx = view.getContext('2d');
  const stain = document.getElementById('stain');
  const sctx = stain.getContext('2d');

  // Offscreens
  const proc = document.createElement('canvas');
  const pctx = proc.getContext('2d', { willReadFrequently: true });
  const maskCanvas = document.createElement('canvas');
  const maskCtx = maskCanvas.getContext('2d');

  // Fit canvases to container at device pixel ratio
  function fit(){
    const dpr = Math.max(1, window.devicePixelRatio || 1);
    const rect = view.getBoundingClientRect();
    const w = Math.max(2, Math.round(rect.width  * dpr));
    const h = Math.max(2, Math.round(rect.height * dpr));
    [view, stain, proc, maskCanvas].forEach(c => { c.width = w; c.height = h; });
  }
  new ResizeObserver(fit).observe(document.body);

  // Video source: autostart webcam (secure origin required: https or http://localhost)
  const vid = document.createElement('video');
  vid.playsInline = true; vid.muted = true; vid.autoplay = true;

  let mediaStream = null;
  async function startWebcam(){
    try{
      stopWebcam();
      mediaStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
      vid.srcObject = mediaStream;
      await vid.play();
    }catch(e){
      // Fallback: support ?src=clip.mp4 for testing without camera
      const qs = new URLSearchParams(location.search);
      const src = qs.get('src');
      if(src){ vid.src = src; vid.play().catch(()=>{}); }
    }
  }
  function stopWebcam(){
    if(mediaStream){ mediaStream.getTracks().forEach(t=>t.stop()); mediaStream=null; }
  }

  // Draw current video frame scaled to FILL the canvas
  function drawFit(ctx, video, W, H, blurPx){
    ctx.save();
    ctx.clearRect(0,0,W,H);
    if(blurPx>0) ctx.filter = `blur(${blurPx}px)`;
    const vw = video.videoWidth || 0, vh = video.videoHeight || 0;
    if(vw && vh){
      const s = Math.max(W/vw, H/vh); // cover
      const dw = Math.round(vw*s), dh = Math.round(vh*s);
      const dx = Math.floor((W - dw)/2), dy = Math.floor((H - dh)/2);
      ctx.drawImage(video, dx, dy, dw, dh);
    }
    ctx.restore();
  }

  // Simple ring buffer of past frames (for Δt diffs)
  const buf = []; const MAX_SEC = 14;
  function pushFrame(imgData, t){
    buf.push({ t, data: new Uint8ClampedArray(imgData.data), w: imgData.width, h: imgData.height });
    const cutoff = t - (MAX_SEC + 2);
    while(buf.length && buf[0].t < cutoff) buf.shift();
  }
  function getPastFrame(delta){
    const target = vid.currentTime - delta;
    for(let i=buf.length-1;i>=0;i--) if(buf[i].t <= target) return buf[i];
    return buf[0] || null;
  }

  // Render loop
  function tick(){
    requestAnimationFrame(tick);
    if(vid.readyState < 2) return;

    const W = view.width, H = view.height;

    // Current frame
    drawFit(pctx, vid, W, H, PARAMS.blur);
    const curr = pctx.getImageData(0,0,W,H);
    pushFrame(curr, vid.currentTime);

    const past = getPastFrame(PARAMS.dt);
    if(!past) return;

    // Diff + composite
    const c = curr.data, p = past.data;
    const out = vctx.createImageData(W,H);
    const od  = out.data;
    const md  = new Uint8ClampedArray(W*H);
    const thr = PARAMS.thr, grey = PARAMS.grey;

    for(let i=0, j=0; i<c.length; i+=4, j++){
      const r=c[i], g=c[i+1], b=c[i+2];
      const pr=p[i], pg=p[i+1], pb=p[i+2];
      const lc = r*0.2126 + g*0.7152 + b*0.0722;
      const lp = pr*0.2126 + pg*0.7152 + pb*0.0722;
      const d = Math.abs(lc - lp);

      if(d > thr){
        md[j]=255;
        od[i]   = (r + (255 - pr)) * 0.5;
        od[i+1] = (g + (255 - pg)) * 0.5;
        od[i+2] = (b + (255 - pb)) * 0.5;
        od[i+3] = 255;
      } else {
        md[j]=0;
        od[i]=od[i+1]=od[i+2]=grey; od[i+3]=255;
      }
    }
    vctx.putImageData(out, 0, 0);

    // Residual staining
    if(PARAMS.stainOn){
      // decay (fade the existing stain)
      sctx.globalCompositeOperation = 'destination-out';
      sctx.fillStyle = `rgba(0,0,0,${1 - PARAMS.decay})`;
      sctx.fillRect(0,0,W,H);
      sctx.globalCompositeOperation = 'source-over';

      // build alpha mask from motion pixels
      const mImg = maskCtx.createImageData(W,H);
      const mdat = mImg.data;
      for(let j=0, k=0; j<md.length; j++, k+=4){
        const v = md[j];
        mdat[k]=mdat[k+1]=mdat[k+2]=v; mdat[k+3]=v;
      }
      maskCtx.putImageData(mImg, 0, 0);

      // colorize + apply strength
      maskCtx.globalCompositeOperation = 'source-in';
      maskCtx.fillStyle = PARAMS.color;
      maskCtx.globalAlpha = PARAMS.strength;
      maskCtx.fillRect(0,0,W,H);
      maskCtx.globalAlpha = 1;
      maskCtx.globalCompositeOperation = 'source-over';

      // add to stain
      sctx.drawImage(maskCanvas, 0, 0);
    }

    // Composite stain over view
    if(PARAMS.stainOn){
      vctx.globalCompositeOperation = 'multiply';
      vctx.drawImage(stain, 0, 0);
      vctx.globalCompositeOperation = 'source-over';
    }
  }

  // Start
  fit();
  requestAnimationFrame(tick);
  startWebcam();
  window.addEventListener('beforeunload', stopWebcam);
})();
</script>
</body>
</html>
